{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutioneel Neuraal Netwerk\n",
    "\n",
    "In deze opdracht ga je een model opbouwen om op basis van een aantal MRI-scans te detecteren of een persoon een hersentumor heeft of niet.\n",
    "\n",
    "Hiervoor maken we gebruik van [deze dataset](https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection) die een 253 scans bevat.\n",
    "\n",
    "Doorheen deze oefening ga je de volgende stappen uitvoeren:\n",
    "* Data downloaden en inladen\n",
    "* Data augmentation\n",
    "* Data modelling\n",
    "* Model evaluation\n",
    "\n",
    "Plaats je code voor deze delen in de stappen hieronder. Vergeet ook zeker niet de bijhorende vragen te beantwoorden.\n",
    "\n",
    "**Opgepast:** Laat de output staan zodat het eenvoudiger is om je bekomen resultaten te interpreteren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plaats alle benodigde imports hier\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import opendatasets as od\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data downloaden en inladen\n",
    "\n",
    "Download in de code-cellen hieronder de dataset en lees deze in. Zorg ervoor dat je een trainings en validatiedata hebt.\n",
    "Een testset moet niet apart gehouden worden\n",
    "Om de dataset in te laden kan je de ImageFolder klasse gebruiken van pytorch.\n",
    "\n",
    "Zorg er ook voor dat er aan data augmentation gedaan wordt. \n",
    "Voorzie dat er minstens drie verschillende augmentations uitgevoerd worden. \n",
    "\n",
    "Vragen:\n",
    "* Hoe is de dataset gestructureerd?\n",
    "* Hoe vind je de labels?\n",
    "* Is er een splitsing tussen trainings/validatie/testdata of moet je dit zelf verzorgen?\n",
    "* Hoeveel beelden kan je overhouden voor validatiedata?\n",
    "* Met het aantal beelden in deze dataset: op welke manieren kan je er toch voor zorgen dat je een goed getrained model kan bekomen.\n",
    "  Wat zijn de belangrijkste parameters van de verschillende augmentation lagen? Wat is het effect van deze parameter. **Let op:** Wees hierbij zo volledig mogelijk. Geef dus niet alleen de waarde van de parameters maar ook de beschrijving van het effect van die parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Antwoord:**\n",
    "\n",
    "Hoe is de dataset gestructureerd?\n",
    "\n",
    "De dataset is gestructureerd in twee hoofdmappen: één map voor positieve gevallen (met hersentumor) en één voor negatieve gevallen (zonder hersentumor). De afbeeldingen zijn in deze mappen onderverdeeld.\n",
    "\n",
    "Hoe vind je de labels?\n",
    "\n",
    "De labels worden automatisch toegewezen op basis van de mapnamen. PyTorch’s ImageFolder klasse gebruikt de namen van de submappen (yes voor tumor en no voor geen tumor) om de labels toe te wijzen.\n",
    "\n",
    "Is er een splitsing tussen trainings/validatie/testdata of moet je dit zelf verzorgen?\n",
    "\n",
    "Nee, de dataset komt niet met een vooraf bepaalde splitsing. Je moet de splitsing zelf verzorgen. In de code gebruiken we een splitsing van 80% voor de trainingsset en 20% voor de validatieset.\n",
    "\n",
    "Hoeveel beelden kan je overhouden voor validatiedata?\n",
    "\n",
    "De dataset bevat 253 beelden. Met een splitsing van 80/20 houd je ongeveer 50 beelden over voor validatiedata en 203 voor training.\n",
    "\n",
    "Met het aantal beelden in deze dataset: op welke manieren kan je er toch voor zorgen dat je een goed getrained model kan bekomen?\n",
    "\n",
    "Je kunt gebruik maken van data augmentation om meer variatie toe te voegen aan de trainingsset, bijvoorbeeld door afbeeldingen willekeurig te spiegelen, roteren of croppen. Hierdoor lijkt de dataset groter en leert het model beter te generaliseren. Daarnaast kan je ook transfer learning gebruiken, waarbij je een model dat al getraind is op een vergelijkbare taak verder finetunet op deze dataset.\n",
    "\n",
    "Wat zijn de belangrijkste parameters van de verschillende augmentation lagen? Wat is het effect van deze parameter?\n",
    "\n",
    "- RandomHorizontalFlip: Flipt afbeeldingen horizontaal met een bepaalde kans \n",
    "  (meestal 50%). Dit vergroot de variëteit in oriëntering van de data.\n",
    "\n",
    "- RandomRotation: Roteert de afbeelding willekeurig binnen een gegeven hoek     (bijv. 10 graden). Dit helpt om variaties in oriëntatie te simuleren.\n",
    "\n",
    "- RandomResizedCrop: Cropt willekeurig een deel van de afbeelding en schaalt    het terug naar de gewenste resolutie (bijv. 224x224). Dit simuleert zoom-in   variaties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./brain-mri-images-for-brain-tumor-detection\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "# downloaden dataset\n",
    "od.download('https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasetlocatie\n",
    "data_dir = os.path.join('brain-mri-images-for-brain-tumor-detection', 'brain_tumor_dataset')\n",
    "# Data-augmentatie: rotatie, flip, normalisatie\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Laad dataset en splits in train/validatie (80/20)\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Dataloaders voor train/validatie\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data modelling\n",
    "\n",
    "Stel nu door gebruik te maken van het pytorch framework een convolutioneel neuraal netwerk op met minstens 3 convolutionele lagen.\n",
    "Zorg dat de structuur van het neuraal netwerk voldoet aan de best practices gezien in de les.\n",
    "Train het model en toon een geschiedenis van het leerproces waarbij je kijkt naar de accuracy, precision en recall.\n",
    "\n",
    "Vragen:\n",
    "* Geef een korte beschrijving van hoe de verschillende types lagen werken. \n",
    "* Waarom is het aangeraden om met convolutionele lagen te werken ipv fully-connected lagen?\n",
    "* Welke types hyperparameter heb je gebruikt in de verschillende lagen. Wees opnieuw ook hier voldoende duidelijk door de betekenis van de hyperparameter op de tensors uit te leggen. (max 5 zinnen per parameter)\n",
    "* Geef hieronder voor elke laag (niet van het data augmentation gedeelte) weer welke hyperparameters je gekozen hebt en welke input en output dimensies er verwacht worden. Een voorbeeld van de verwachte output zie je hieronder.\n",
    "* Welke loss functie heb je nodig en waarom?\n",
    "* Wat is de activatiefunctie in de laatste laag en waarom?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Antwoord:**\n",
    "\n",
    "* Laag 1: Convolutionele Laag\n",
    "    * Input dimensies: 200 x 200 x 3\n",
    "    * Output dimensies: ....\n",
    "    * Num kernels:\n",
    "    * Kernel size:\n",
    "    * Stride: \n",
    "    * Padding: \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definieer het CNN-model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        # Convolutionele laag 1: input channels=3 (kleur), output channels=16\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        # Max pooling\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # 2 output classes: tumor/geen tumor\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Convolutie 1 met activatiefunctie en pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Convolutie 2 met activatiefunctie en pooling\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # Convolutie 3 met activatiefunctie en pooling\n",
    "        x = x.view(-1, 64 * 28 * 28)         # Flatten voor FC-lagen\n",
    "        x = F.relu(self.fc1(x))              # Fully connected laag 1\n",
    "        x = self.fc2(x)                      # Fully connected laag 2\n",
    "        return x\n",
    "\n",
    "# Instantieer het model\n",
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functie en optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train het model\n",
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0.0, 0, 0\n",
    "        for data in train_loader:\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Bereken accuracy, precision, recall voor elke epoch\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "            all_preds, all_labels = [], []\n",
    "            for data in val_loader:\n",
    "                inputs, labels = data\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                all_preds.extend(predicted.tolist())\n",
    "                all_labels.extend(labels.tolist())\n",
    "\n",
    "            accuracy = 100 * val_correct / val_total\n",
    "            precision = precision_score(all_labels, all_preds, average='macro')\n",
    "            recall = recall_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "            print(f'Epoch {epoch+1}, Loss: {train_loss:.3f}, Val Loss: {val_loss:.3f}, '\n",
    "                  f'Accuracy: {accuracy:.2f}%, Precision: {precision:.2f}, Recall: {recall:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beschrijving van lagen:\n",
    "\n",
    "Convolutionele lagen gebruiken filters (kernels) om kenmerken te extraheren zoals randen of patronen in de afbeelding.\n",
    "Max pooling reduceert de dimensies van de output, behoudt belangrijke kenmerken, en vermindert overfitting.\n",
    "Fully connected lagen verbinden elke neuron in de vorige laag met elke neuron in de volgende, wat helpt bij classificatie.\n",
    "Waarom convolutionele lagen?\n",
    "\n",
    "Convolutionele lagen zijn beter geschikt voor afbeeldingen omdat ze de lokale ruimtelijke verbanden in de data kunnen vastleggen, terwijl fully-connected lagen alle input tegelijk verwerken, wat inefficiënt is voor beelddata.\n",
    "Hyperparameters per laag:\n",
    "\n",
    "Num kernels: Aantal filters bepaalt hoeveel kenmerken elk niveau van convolutie kan leren (meer filters → complexere kenmerken).\n",
    "Kernel size: Grootte van de filter bepaalt welk gebied de kernel bekijkt. Grotere kernels vangen meer globale kenmerken, kleine meer lokale.\n",
    "Stride: Stapgrootte van de kernel. Een stride van 1 behoudt de meeste informatie; een hogere stride verkleint de output sneller.\n",
    "Padding: Voegt randen toe aan de input, wat helpt bij het behouden van de resolutie na convolutie.\n",
    "Loss functie:\n",
    "\n",
    "CrossEntropyLoss is geschikt voor classificatieproblemen met meerdere klassen, omdat het het verschil meet tussen de voorspelde probabiliteiten en de werkelijke labels.\n",
    "Activatiefunctie in de laatste laag:\n",
    "\n",
    "In de laatste laag wordt geen activatiefunctie gebruikt, omdat de cross-entropy loss functie intern een softmax berekening doet over de output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_metrics(history):\n",
    "    epochs = range(1, len(history['accuracy']) + 1)\n",
    "    plt.plot(epochs, history['accuracy'], label='Accuracy')\n",
    "    plt.plot(epochs, history['precision'], label='Precision')\n",
    "    plt.plot(epochs, history['recall'], label='Recall')\n",
    "    plt.title('Model Performance')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "\n",
    "Na het trainen van het model kunnen we evalueren of het gebouwde model goed werkt.\n",
    "\n",
    "Beantwoord hiervoor de volgende vragen:\n",
    "* Maak een plot van de trainings error en validation accuracy van de getrainde model modellen\n",
    "* Bespreek op basis van deze figuren of het model aan het over/underfitten is.\n",
    "* Hoe zou je overfitten tegengaan?\n",
    "* Hoe zou je underfitten tegengaan?\n",
    "* Bereken voor de valuatiedata ook de precision, recall en f1-score. Welk van deze metrieken is belangrijk voor deze dataset als we geen false positives willen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Antwoorden:...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbeterde model\n",
    "\n",
    "Maak nu een tweede model dat probeert betere resultaten te halen dan het bovenstaande model.\n",
    "Hierbij mag je gebruik maken van alle technieken die je wil.\n",
    "Er is hierbij maar 1 voorwaarde: **maak gebruik van de torch.nn.BatchNorm2d layer**.\n",
    "Train en evalueer dit model ook en vergelijk het met het vorige.\n",
    "Indien je bij het vorige model over/underfitting opgemerkt hebt, pak dit aan in dit model.\n",
    "\n",
    "Vragen:\n",
    "* Bespreek de structuur van het model (niet elke hyperparameter meer maar enkel de gekozen lagen). Waarom heb je de wijzigingen doorgevoerd?\n",
    "* Wat doet de batchnormalization layer? Wat is de beste plaats voor deze laag toe te voegen?\n",
    "* Bespreek hoe je over/underfitting hebt aangepakt\n",
    "* Bespreek de behaalde resultaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Antwoord:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model met batchnormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5e8e3a19af5ceb2434683dff87da6345c3b29f7eb0a8a138558c07d014a01cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
