{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4546c4a-95ce-4bf5-b09e-fd32d2d4c954",
   "metadata": {},
   "source": [
    "# Image segmentation\n",
    "\n",
    "In dit voorbeeld zullen we gebruik maken van de Oxford Pets Dataset. Het model zal leren om objecten (bijv. huisdieren) van de achtergrond te onderscheiden.\n",
    "We gebruiken hiervoor de U-Net architectuur, een populair model voor afbeeldingssegmentatie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8474f9c-7f92-4dd2-8649-6fd34fd83abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import opendatasets as od\n",
    "import tarfile\n",
    "\n",
    "# Controleren of GPU beschikbaar is\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08971940-f017-412a-88bd-5a71df31fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "od.download(\"http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\", data_dir=\"oxford\")\n",
    "od.download(\"http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\", data_dir=\"oxford\")\n",
    "\n",
    "# Open het .tar.gz bestand\n",
    "with tarfile.open(\"oxford/images.tar.gz\", \"r:gz\") as tar:\n",
    "    # Pak alle inhoud uit naar de \"oxford/images\" directory\n",
    "    tar.extractall(path=\"oxford\")\n",
    "\n",
    "# Open het .tar.gz bestand\n",
    "with tarfile.open(\"oxford/annotations.tar.gz\", \"r:gz\") as tar:\n",
    "    # Pak alle inhoud uit naar de \"oxford/images\" directory\n",
    "    tar.extractall(path=\"oxford\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e53b5d-14c4-406b-8269-4e8dc5b465d9",
   "metadata": {},
   "source": [
    "## Dataset inladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc756d13-861e-4e06-8c9f-8229f1dad38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 572, 572])\n",
      "torch.Size([8, 388, 388])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Transformeer de afbeeldingen en maskers\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((572, 572)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class OxfordPetsDataset(data.Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted([f for f in os.listdir(os.path.join(root, 'images')) if f.endswith('.jpg')])\n",
    "        self.mask_files = sorted([f for f in os.listdir(os.path.join(root, 'annotations/trimaps')) if f.endswith('.png') and not f.startswith(\".\")])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root, 'images', self.image_files[idx])\n",
    "        mask_path = os.path.join(self.root, 'annotations/trimaps', self.mask_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask = Image.open(mask_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = transforms.PILToTensor()(mask)\n",
    "            mask = transforms.Resize((388, 388))(mask)\n",
    "          \n",
    "        # Segmentatiemaskers zijn geannoteerd met waarden 1, 2, 3\n",
    "        mask = mask.squeeze(0)  # Verwijder kanaal 0, aangezien het grijswaarden zijn\n",
    "        mask = torch.where(mask >= 2.0, torch.ones_like(mask, dtype=torch.float), torch.zeros_like(mask, dtype=torch.float))  # Mwaarde 2 omzetten naar 1, andere 0)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "# Pad naar de dataset\n",
    "root = './oxford'\n",
    "\n",
    "# Laad de dataset\n",
    "train_dataset = OxfordPetsDataset(root=root, transform=transform)\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "for images, mask in train_loader:\n",
    "    print(images.shape)\n",
    "    print(mask.shape)\n",
    "    print(mask.max())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8a70bd-ddea-40eb-ad91-5dedfcb451ca",
   "metadata": {},
   "source": [
    "## Samenstellen van het U-net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7484d73-5bba-404f-9b51-a98c56e7ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__() # constructor base-class\n",
    "\n",
    "        # encoder\n",
    "        self.enc_block1 = self.conv_block(3, 64)\n",
    "        self.enc_block2 = self.conv_block(64, 128)\n",
    "        self.enc_block3 = self.conv_block(128, 256)\n",
    "        self.enc_block4 = self.conv_block(256, 512)\n",
    "\n",
    "        # bottleneck\n",
    "        self.bottleneck = self.conv_block(512, 1024)\n",
    "\n",
    "        # decoder\n",
    "        self.dec_block1 = self.conv_block(1024 + 512, 512) # bottleneck + enc_block4\n",
    "        self.dec_block2 = self.conv_block(512+256, 256) # dec_block1 + enc_block3\n",
    "        self.dec_block3 = self.conv_block(256+128, 128)\n",
    "        self.dec_block4 = self.conv_block(128+64, 64)\n",
    "\n",
    "        # de 1 hier bepaalt hoeveel klassen we toelaten. In dit geval 1 want binaire classificatie (huisdier of niet)\n",
    "        # als er meer opties zijn: is het 1 per klasse (en eventueel 1 extra voor background)\n",
    "        self.final_conv = nn.Conv2d(64, 1, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        enc_block1 = self.enc_block1(x)\n",
    "        #print(enc_block1.shape)\n",
    "        enc_block2 = self.enc_block2(self.maxpool(enc_block1))\n",
    "        #print(enc_block2.shape)\n",
    "        enc_block3 = self.enc_block3(self.maxpool(enc_block2))\n",
    "        #print(enc_block3.shape)\n",
    "        enc_block4 = self.enc_block4(self.maxpool(enc_block3))\n",
    "        #print(enc_block4.shape)\n",
    "\n",
    "        # bottleneck\n",
    "        bottleneck = self.bottleneck(self.maxpool(enc_block4))\n",
    "\n",
    "        # decoder\n",
    "        dec_block1 = self.upsample_and_concat(bottleneck, enc_block4) # voeg bottleneck en enc_block4\n",
    "        dec_block1 = self.dec_block1(dec_block1)\n",
    "        \n",
    "        dec_block2 = self.upsample_and_concat(dec_block1, enc_block3) # voeg bottleneck en enc_block4\n",
    "        dec_block2 = self.dec_block2(dec_block2)\n",
    "        \n",
    "        dec_block3 = self.upsample_and_concat(dec_block2, enc_block2) # voeg bottleneck en enc_block4\n",
    "        dec_block3 = self.dec_block3(dec_block3)\n",
    "        \n",
    "        dec_block4 = self.upsample_and_concat(dec_block3, enc_block1) # voeg bottleneck en enc_block4\n",
    "        dec_block4 = self.dec_block4(dec_block4)\n",
    "\n",
    "        output = torch.sigmoid(self.final_conv(dec_block4)) # sigmoid want binary classification\n",
    "        return output\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, stride=1, kernel_size=3, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, stride=1, kernel_size=3, padding=0),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def upsample_and_concat(self, x1, x2):\n",
    "        x1 = nn.functional.interpolate(x1, scale_factor=2, mode='bilinear')\n",
    "        x2 = torchvision.transforms.functional.resize(x2, x1.shape[2])\n",
    "        return torch.cat([x1, x2], dim=1)\n",
    "\n",
    "model = UNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd905be4-8eaa-4fd3-acca-e53a30e5c4f4",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee4d75f-9420-49fe-ae02-78f1dd46c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs=2\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device) # stuur het naar de gpu als je er 1 hebt\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        #print(outputs.shape)\n",
    "        #print(outputs.max())\n",
    "        #break\n",
    "        loss = criterion(outputs, masks.unsqueeze(1))\n",
    "        loss.backward()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch {epoch}: running loss is {running_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e85619b-045a-4bb0-8f90-c7cb5ffadf6f",
   "metadata": {},
   "source": [
    "## Evaluatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b6daad-fc99-4122-b651-4eca002954b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalueren en Visualiseren\n",
    "model.eval()\n",
    "\n",
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    \n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i].cpu().numpy().squeeze(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Testen op enkele voorbeelden\n",
    "with torch.no_grad():\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        predictions = model(images)\n",
    "        print(masks[0].unique())\n",
    "        predictions = (predictions > 0.5).float()  # Thresholding\n",
    "        display([images[0].permute(1, 2, 0), masks[0], predictions[0]])\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bd0b77-e172-412c-b631-065ea2ec3ea2",
   "metadata": {},
   "source": [
    "## Oefening\n",
    "\n",
    "Herbouw het bovenstaande model met Keras, zorg er ook voor dat de loss bestudeerd kan worden met tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594e06dc-719c-4588-b10b-f7cd7153a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669fb4a2-3602-4548-9d76-e4fc038932f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84064d60-630f-4fd6-a84b-29f800f1b6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5618eb5-610d-4027-93d4-a65cc53679e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
