{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ece9ec2a-8afa-4f7f-bfe9-0609d1100f6b",
   "metadata": {},
   "source": [
    "# Classificatie van nieuwsartikelen\n",
    "\n",
    "In deze notebook gaan we verder werken op de AG-news nieuwsartikelen dataset.\n",
    "In de vorige notebook hebben we bekeken hoe we tekstuele data kunnen preprocessen.\n",
    "In deze notebook gaan we classificatie uitvoeren door gebruik te maken van recurrente neurale netwerken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7c6d37-e785-4177-9e0d-8cebff1cbd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./ag-news-classification-dataset\" (use force=True to force download)\n",
      "Using device: cuda\n",
      "Skipping, found downloaded files in \"./ag-news-classification-dataset\" (use force=True to force download)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              title  \\\n",
       "0      2  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1      2  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2      2    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3      2  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4      2  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...   \n",
       "1  Reuters - Private investment firm Carlyle Grou...   \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...   \n",
       "3  Reuters - Authorities have halted oil export\\f...   \n",
       "4  AFP - Tearaway world oil prices, toppling reco...   \n",
       "\n",
       "                                                text  \n",
       "0  Wall St. Bears Claw Back Into the Black (Reute...  \n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...  \n",
       "2  Oil and Economy Cloud Stocks' Outlook (Reuters...  \n",
       "3  Iraq Halts Oil Exports from Main Southern Pipe...  \n",
       "4  Oil prices soar to all-time record, posing new...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import opendatasets as od\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset\")\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the dataset\n",
    "od.download(\"https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset\")\n",
    "\n",
    "# Load the dataset\n",
    "def read_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df.columns = [\"label\", \"title\", \"description\"]\n",
    "    df[\"text\"] = df['title'] + ' ' + df['description']\n",
    "    df['label'] = df['label'] - 1\n",
    "    return df\n",
    "\n",
    "df_train = read_csv('./ag-news-classification-dataset/train.csv')\n",
    "display(df_train.head())\n",
    "\n",
    "df_test = read_csv('./ag-news-classification-dataset/test.csv')\n",
    "\n",
    "# parameters\n",
    "MAX_NUM_WORDS = 20000  # aantal woorden in de woordenboek\n",
    "MAX_SEQ_LENGTH = 50     # maximum lengte van een zin\n",
    "EMBEDDING_DIM = 60      # elk woordje wordt voorgesteld door dit aantal getallen\n",
    "\n",
    "def preprocess(df, tokenizer=None):\n",
    "    # deze functie gaat de tekst in tokens gaan verdelen\n",
    "    if tokenizer is None:\n",
    "        tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "        tokenizer.fit_on_texts(df.text)\n",
    "    \n",
    "    sequences = tokenizer.texts_to_sequences(df.text) # tokenize de string en zet het om naar getallen\n",
    "    x = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH) # voer padding en truncating uit\n",
    "\n",
    "    y = to_categorical(df.label, num_classes=4) # zet het ordinal encoded om naar onehot encoded\n",
    "\n",
    "    return x, y, tokenizer\n",
    "\n",
    "X_train, y_train, tokenizer = preprocess(df_train)\n",
    "X_test, y_test, _ = preprocess(df_test, tokenizer)\n",
    "\n",
    "# Dataset + dataloader\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text, labels):\n",
    "        super(TextDataset, self).__init__()\n",
    "        self.text = text\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.text[idx], dtype=torch.long) \n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "train_dataset = TextDataset(X_train, y_train)\n",
    "test_dataset = TextDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# train_loader wordt meerdere keren doorlopen -> volgorde veranderen kan helpen\n",
    "# test_loader wordt typisch maar 1 keer doorlopen voor evaluatie (volgorde niet belangrijk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdd6c70-ace6-4e59-8973-b6a60f61fadf",
   "metadata": {},
   "source": [
    "## Opbouwen, trainen en evalueren van een RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ad0eb4e-4312-462d-a34f-bd3c71ead5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 50]) torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n"
     ]
    }
   ],
   "source": [
    "# RNN model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(MAX_NUM_WORDS, EMBEDDING_DIM)\n",
    "        self.rnn = nn.RNN(EMBEDDING_DIM, hidden_size, batch_first=True)\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, state = self.rnn(x)\n",
    "        x = self.output(x[:, -1]) # enkel geinteresseerd in de laatste ouput van het rnn (many-to-one)\n",
    "        return x\n",
    "\n",
    "model = RNNModel(128, 4)\n",
    "\n",
    "for inputs, labels in train_loader:\n",
    "    print(inputs.shape, labels.shape)\n",
    "    x = model(inputs)\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1edbc6b9-60b4-44ad-b943-13ef276b0555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/5 -> loss = 0.8217456340471904\n",
      "Epoch 1/5 -> loss = 0.5581653375784557\n",
      "Epoch 2/5 -> loss = 0.43263132269382476\n",
      "Epoch 3/5 -> loss = 0.3845697767178218\n",
      "Epoch 4/5 -> loss = 0.34513167934417727\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Train het Model\n",
    "num_epochs = 5\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # merk op dat er geen verschil is in het trainingsproces\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch}/{num_epochs} -> loss = {running_loss/len(train_loader)}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9eb57af5-0ff0-499f-94be-35e7e5ea89e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.8611)\n"
     ]
    }
   ],
   "source": [
    "# Evalueer het Model\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        labels = torch.argmax(labels, 1)\n",
    "        predicted = torch.argmax(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted==labels).sum()\n",
    "\n",
    "print(\"Accuracy:\", correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6277e4fc-e559-4f43-8d88-1840cc31dc52",
   "metadata": {},
   "source": [
    "## Oefeningen\n",
    "\n",
    "* Voeg een extra Dense-laag toe na de RNN-laag. Experimenteer met het aantal neuronen in deze laag en analyseer hoe de prestaties veranderen.\n",
    "* Pas het model aan om in plaats van een SimpleRNN-laag een LSTM of GRU-laag te gebruiken. Vergelijk de prestaties van de drie typen recurrente netwerken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991aec0-9549-4d1b-99fb-897d2331fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oefening 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7775c80b-0838-4a41-848a-25c499141be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oefening 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a7182-6e98-40a4-953d-3051cb8687a9",
   "metadata": {},
   "source": [
    "**Oefening 3**\n",
    "\n",
    "Volg de tutorial op de volgende link: https://www.tensorflow.org/text/tutorials/text_generation\n",
    "Werk hieronder het gelijkaardige probleem uit maar maak het door gebruik te maken van pytorch in plaats van tensorflow voor het model op te bouwen.\n",
    "In deze tutorial wordt er tekst gegenereerd die lijkt op tekst geschreven door shakespeare.\n",
    "Let op dat dit een vereenvoudigde versie is waarbij karakter per karakter wordt gegenereerd en niet woord per woord. Er is dus geen garantie dat er echte woorden gemaakt worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab02f2-fa9f-4306-8ad2-a378b45eb9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import random\n",
    "\n",
    "path_to_file = keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "print(f'Length of text: {len(text)} characters')\n",
    "print(text[:250])\n",
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')\n",
    "\n",
    "# Character to index mapping\n",
    "char_to_idx = {char: idx for idx, char in enumerate(vocab)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(vocab)}\n",
    "\n",
    "# TODO: Encodeer elk karakter in tekst naar een nummer, uitkomst is een list ipv een string\n",
    "\n",
    "# TODO: Maak een dataset aan waarbij de tekst (uit voorgaande todo) omzet naar een reeks sequenties\n",
    "# input 100 aaneensluitende karakters, output is het karakter erop volgende\n",
    "\n",
    "# TODO: indien nodig maak een subset tot 10 of 1% van de dataset\n",
    "\n",
    "# Check a single example\n",
    "sample_x, sample_y = dataset[0]\n",
    "print(\"Input (x):\", sample_x)\n",
    "print(\"Target (y):\", sample_y)\n",
    "print(\"Decoded Input:\", ''.join(idx_to_char[idx] for idx in sample_x.numpy()))\n",
    "print(\"Decoded Target:\", idx_to_char[sample_y.item()])\n",
    "print('Rows', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b060e-a61f-4a32-9dcd-ba625ebc222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Maak een rnn model bestaande uit een embedding layer, gru layer en linear layer\n",
    "# Maak het mogelijk om aan de forward funtie een parameter toe te voegen om ook de hidden state terug te geven en om de hidden state mee te geven voor de gru laag\n",
    "# \n",
    "vocab_size = len(idx_to_char)\n",
    "print(vocab_size)\n",
    "embedding_dim = 50\n",
    "rnn_units = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd60acb-29d3-4087-b7a9-8f64b2c9fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 1 sample om door het model te sturen\n",
    "# kijk of je dimensies correct aan elkaar gekoppeld zijn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fbb345-d9f0-477a-98c2-2aa83db41963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import math\n",
    "\n",
    "batch_size = 64\n",
    "seq_length = 100\n",
    "epochs = 5\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 50\n",
    "rnn_units = 60\n",
    "\n",
    "shakespeare = ShakespeareModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "\n",
    "# TODO: train het rnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec92677b-7f6b-4cb1-9f6b-faf2da8a68b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_text(model, start_string, char_to_idx, idx_to_char, vocab_size, generation_length=100, temperature=1.0):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # Convert start_string to indices\n",
    "    input_indices = torch.tensor([char_to_idx[char] for char in start_string], dtype=torch.long).unsqueeze(0)\n",
    "    \n",
    "    generated_text = start_string\n",
    "    states = None  # Initial state (None means it will be initialized automatically)\n",
    "    \n",
    "    for _ in range(generation_length):\n",
    "        # Genereer opeenvolgend nieuwe tokens\n",
    "        pass\n",
    "    \n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d49248-9fad-4174-a5a1-af319bcfc38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example start string and generation parameters\n",
    "start_string = \"ROMEO: \"\n",
    "generation_length = 200\n",
    "temperature = 0.8\n",
    "\n",
    "# Generate text\n",
    "generated_text = generate_text(\n",
    "    model=shakespeare,\n",
    "    start_string=start_string,\n",
    "    char_to_idx=char_to_idx,\n",
    "    idx_to_char=idx_to_char,\n",
    "    vocab_size=vocab_size,\n",
    "    generation_length=generation_length,\n",
    "    temperature=temperature\n",
    ")\n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645098d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5489145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
